<!DOCTYPE html>
<html lang="">
  <head>
    
<meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width,user-scalable=no,initial-scale=1,minimum-scale=1,maximum-scale=1">


<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />



  <meta name="description" content="Web spider[打开链接]]"/>




  <meta name="keywords" content="Web_spider," />





    <link rel="alternate" href="/default" title="Lihao">




    <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=1.1"/>



<link rel="canonical" href="https://MineWelt.github.io/2020/01/01/Web-spider-请求响应/"/>


<meta name="description" content="urllib 内置四个模板 :   request : HTTP 请求模板, 可以用来模拟发送请求. error : 异常处理模块, 用以保证程序不会异常中断. parse : 工具模板, 提供了很多的 URL 处理方法.(拆分, 解析, 合并等) robotparser : 主要识别网站的 robots.txt 文件, 然后判断哪些网站可以爬取.   urlopen()在python的官方文档中">
<meta name="keywords" content="Web_spider">
<meta property="og:type" content="article">
<meta property="og:title" content="Web spider[打开链接]]">
<meta property="og:url" content="https:&#x2F;&#x2F;minewelt.github.io&#x2F;2020&#x2F;01&#x2F;01&#x2F;Web-spider-%E8%AF%B7%E6%B1%82%E5%93%8D%E5%BA%94&#x2F;index.html">
<meta property="og:site_name" content="Lihao">
<meta property="og:description" content="urllib 内置四个模板 :   request : HTTP 请求模板, 可以用来模拟发送请求. error : 异常处理模块, 用以保证程序不会异常中断. parse : 工具模板, 提供了很多的 URL 处理方法.(拆分, 解析, 合并等) robotparser : 主要识别网站的 robots.txt 文件, 然后判断哪些网站可以爬取.   urlopen()在python的官方文档中">
<meta property="og:locale" content="zh-CN">
<meta property="og:updated_time" content="2020-01-09T02:11:26.306Z">
<meta name="twitter:card" content="summary">


<link rel="stylesheet" type="text/css" href="/css/style.css?v=1.1"/>
<link href='https://fonts.googleapis.com/css?family=Open+Sans' rel='stylesheet'>





<script type="text/javascript">
  var themeConfig = {
    fancybox: {
      enable: false
    },
  };
</script>




    





    





    <title> Web spider[打开链接]] - Lihao </title>
  </head>

  <body>
    <div id="page">
      <header id="masthead"><div class="site-header-inner">
    <h1 class="site-title">
        <a href="/." class="logo">Lihao</a>
    </h1>

    <nav id="nav-top">
        
            <ul id="menu-top" class="nav-top-items">
                
                    <li class="menu-item">
                        <a href="/about">
                            
                            
                                About
                            
                        </a>
                    </li>
                
                
            </ul>
        
    </nav>

</div>

      </header>
      <div id="content">
        
    <div id="primary">
        
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          Web spider[打开链接]]
        
      </h1>

      <time class="post-time">
          1月 1 2020
      </time>
    </header>



    
            <div class="post-content">
            <p>urllib 内置四个模板 : </p>
<ul>
<li>request : HTTP 请求模板, 可以用来模拟发送请求.</li>
<li>error : 异常处理模块, 用以保证程序不会异常中断.</li>
<li>parse : 工具模板, 提供了很多的 URL 处理方法.(拆分, 解析, 合并等)</li>
<li>robotparser : 主要识别网站的 robots.txt 文件, 然后判断哪些网站可以爬取.</li>
</ul>
<hr>
<h4 id="urlopen"><a href="#urlopen" class="headerlink" title="urlopen()"></a>urlopen()</h4><p>在python的官方文档中, urlopen() 函数的 API ：</p>
<p><code>urllib.request.urlopen(url, data=None, [time,]*, cafile=None, capath=None, cadefault=False, context=None)</code></p>
<p>首先我们看看它的强大之处.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span></pre></td></tr><tr><td class="code"><pre><span class="line"> </span></pre></td></tr><tr><td class="code"><pre><span class="line">response = urllib.request.urlopen(<span class="string">'https://www.baidu.com'</span>)</span></pre></td></tr><tr><td class="code"><pre><span class="line">print(response.read().decode(<span class="string">'utf-8'</span>))</span></pre></td></tr></table></figure>

<p>运行结果如下:</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">&lt;html&gt;</span></pre></td></tr><tr><td class="code"><pre><span class="line">&lt;head&gt;</span></pre></td></tr><tr><td class="code"><pre><span class="line">	&lt;script&gt;</span></pre></td></tr><tr><td class="code"><pre><span class="line">		location.replace(location.href.replace(<span class="string">"https://"</span>,<span class="string">"http://"</span>));</span></pre></td></tr><tr><td class="code"><pre><span class="line">	&lt;/script&gt;</span></pre></td></tr><tr><td class="code"><pre><span class="line">&lt;/head&gt;</span></pre></td></tr><tr><td class="code"><pre><span class="line">&lt;body&gt;</span></pre></td></tr><tr><td class="code"><pre><span class="line">	&lt;noscript&gt;&lt;meta http-equiv="refresh" content="0;url=http://www.baidu.com/"&gt;&lt;/noscript&gt;</span></pre></td></tr><tr><td class="code"><pre><span class="line">&lt;/body&gt;</span></pre></td></tr><tr><td class="code"><pre><span class="line">&lt;/html&gt;</span></pre></td></tr></table></figure>

<p>仅仅两行代码, 便完成了对 pyhton 代码的抓取, 得到了网页的源码之后, 我们可以得到任何想要的信息 : 链接、图片地址、文本信息…</p>
<ul>
<li>data</li>
</ul>
<p>data 参数是可选的， urlopen 的默认的 data 方式是 GET ，给 data 赋值之后它的请求方式就变成了 POST 形式. </p>
<p>需要注意的是, 在 python 的官方文档中, 指定 data 这个参数的形式必须是 urlencode() 的形式, 所以我们需要用到 urllib.parse 模板里面的 urllib.parse.urlencode() 方法.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.parse</span></pre></td></tr><tr><td class="code"><pre><span class="line"> </span></pre></td></tr><tr><td class="code"><pre><span class="line">data = &#123;&#125;</span></pre></td></tr><tr><td class="code"><pre><span class="line">data[<span class="string">'word'</span>] = <span class="string">'hello'</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">data = urllib.parse.urlencode(data).encode(<span class="string">'utf-8'</span>)</span></pre></td></tr><tr><td class="code"><pre><span class="line">response = urllib.request.urlopen(<span class="string">'http://httpbin.org/post'</span>, data = data)  <span class="comment">#此处的url是用来测试POST请求的链接</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">print(response.read())</span></pre></td></tr></table></figure>

<p>运行结果如下:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">&#123;</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="string">"args"</span> : &#123;&#125;,</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="string">"data"</span> : <span class="string">""</span>,</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="string">"files"</span> : &#123;&#125;,</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="string">"form"</span> : &#123;</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="string">"word"</span> : <span class="string">"hello"</span>        <span class="comment">#我们传递的参数出现在了 form 中，表明是模拟了表单的提交方式是以 POST 形式传输数据</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">&#125;,</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="string">"headers"</span> : &#123;</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="string">"Accept-Encoding"</span> : <span class="string">"identity"</span>,</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="string">"Content-Length"</span> : <span class="string">"10"</span>,</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="string">"Content-Type"</span> : <span class="string">"application/x-www-form-urlencode"</span>,</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="string">"Host"</span> : <span class="string">"httpbin.org"</span>,</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="string">"User-Agent"</span> : <span class="string">"Python-urllib/3.8"</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">&#125;,</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="string">"json"</span> : null,</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="string">"origin"</span> : <span class="string">"123.124.23.253"</span>,</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="string">"url"</span> : <span class="string">"http://httpbin.org/post"</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">&#125;</span></pre></td></tr></table></figure>

<ul>
<li>timeout</li>
</ul>
<p>timeout 参数用于设置超时时间，单位是秒, 如果超过这个设定的时间， 就会抛出异常.</p>
<ul>
<li>其他参数</li>
</ul>
<p>详情请移步: <a href="https://docs.python.org/3/library/urllib.request.html" target="_blank" rel="noopener">https://docs.python.org/3/library/urllib.request.html</a></p>
<hr>
<h4 id="Request"><a href="#Request" class="headerlink" title="Request"></a>Request</h4><p>对于简单的请求, urlopen 可以胜任, 但是不足以构成完整的请求. 如果要添加 Headers 等信息， 就要更强大的 Request 类.</p>
<p>实例感受一下:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span></pre></td></tr><tr><td class="code"><pre><span class="line"> </span></pre></td></tr><tr><td class="code"><pre><span class="line">request = urllib.request.Request(<span class="string">'http://python.org'</span>)</span></pre></td></tr><tr><td class="code"><pre><span class="line">response = urllib.request.urlopen(request)</span></pre></td></tr><tr><td class="code"><pre><span class="line">print(response.read().decode(<span class="string">'utf-8'</span>))</span></pre></td></tr></table></figure>

<p>注意, 这里我们依然是用 urlopen 打开， 不同的是， 其参数不再是 url ，而是 Request 对象.</p>
<ul>
<li>Request 的参数构造：</li>
</ul>
<p><code>urllib.request.Request(url, data=None, headers={}, origin_req_host=None, unverifiable=False, method=None)</code></p>
<ul>
<li><p>headers : 是一个字典, 它就是请求头, 添加请求的最常用方法就是 通过修改 User—Agent 来伪装浏览器 , 默认的 Python-urllib.（直接 copy 源码中的 User-Agent ）</p>
</li>
<li><p>origin_req_host : 指的是请求方的 host 名称或者 ip地址.</p>
</li>
<li><p>unverifiable : 是用来表示请求是否无法验证, 默认是False. </p>
</li>
<li><p>method : 是一个字符串, 指示请求的方法, 比如 GET，POST 和 PUT.</p>
</li>
</ul>
<hr>
<h4 id="高级用法"><a href="#高级用法" class="headerlink" title="高级用法"></a>高级用法</h4><p>如果我们需要功能更高级 ( 比如Cookies处理， 代理设置 ) 的请求方式, 就要使用 Handler.</p>
<p><a href="https://docs.python.org/3/library/urllib.request.html#urllib.request.BaseHandler" target="_blank" rel="noopener">https://docs.python.org/3/library/urllib.request.html#urllib.request.BaseHandler</a></p>
<h3 id="requests"><a href="#requests" class="headerlink" title="requests"></a>requests</h3><p>相对于 urlpoen 的含糊不清， 我更喜欢 requests 的简单直接。它可以指明请求方式（POST还是GET），可以进行代理设置，Cookies 设置，添加 headers .</p>
<h4 id="GET"><a href="#GET" class="headerlink" title="GET"></a>GET</h4><ul>
<li>添加 headers</li>
</ul>
<p>现如今，很多网页都禁止爬取，所以有必要添加 headers 来模拟用户访问.</p>
<p><code>requests.get(url, headers = headers)</code></p>
<p>具体用法和 urlopen 一样， 这里就不再复述了.</p>
<ul>
<li>抓取二进制数据</li>
</ul>
<p>其实，图片，音频，视频这些文件都是二进制代码，由于有特殊的保存方式和解码方式所以才会产生不同的结果.所以，如果我们想要获取他们，就要抓取二进制代码.</p>
<ul>
<li>代理设置</li>
</ul>
<p>对于很多网站, 在你测试的时候请求几次之后，能获取正常内容，一旦开始大规模爬取, 网页就会弹出验证页面. 或者禁止你的 ip 访问权限.<br>这时候我们就要选用不同的代理.</p>
<p>而与代理设置有关的参数就是 proxies.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">url = <span class="string">'http://www.baidu.com'</span> </span></pre></td></tr><tr><td class="code"><pre><span class="line">proxies  = &#123;<span class="string">'http'</span>:<span class="string">'http://183.207.224.43:80'</span>,<span class="string">'http'</span>:<span class="string">'http://180.97.34.35:80'</span>&#125;</span></pre></td></tr><tr><td class="code"><pre><span class="line"> </span></pre></td></tr><tr><td class="code"><pre><span class="line">requests.get(url, proxies=proxies)</span></pre></td></tr></table></figure>

<p>当然，我们有需要的话，可以同时把 headers 也塞进去.</p>

            </div>
          

    
      <footer class="post-footer">
        <div class="post-tags">
          
            <a href="/tags/Web-spider/">Web_spider</a>
          
        </div>

        
        
  <nav class="post-nav">
    
      <a class="prev" href="/2020/01/03/Web-spider-%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/">
        <i class="iconfont icon-left"></i>
        <span class="prev-text nav-default">Web_spider[异常处理]</span>
        <span class="prev-text nav-mobile">Prev</span>
      </a>
    
    
      <a class="next" href="/2019/12/31/Python%E7%9A%84%E9%AD%94%E6%B3%95%E6%A3%92/">
        <span class="next-text nav-default">Python的魔法棒</span>
        <span class="prev-text nav-mobile">Next</span>
        <i class="iconfont icon-right"></i>
      </a>
    
  </nav>

        
  <div class="comments" id="comments">
    
  </div>


      </footer>
    
  </article>

    </div>

      </div>

      <footer id="colophon"><span class="copyright-year">
    
        &copy;
    
        2019 -
    
    2020
    <span class="footer-author">Lihao.</span>
    <span class="power-by">
        Powered by <a class="hexo-link" href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> and <a class="theme-link" href="https://github.com/henryhuang/hexo-theme-polarbearsimple" target="_blank" rel="noopener">Polar Bear Simple</a>
    </span>
</span>

<div>
<span id="timeDate">载入天数...</span><span id="times">载入时分秒...</span>
<script>
    var now = new Date();
    function createtime() {
        var grt= new Date("11/29/2019 00:00:00");
        now.setTime(now.getTime()+250);
        days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days);
        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours);
        if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum);
        mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;}
        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);
        snum = Math.round(seconds); if(String(snum).length ==1 ){snum = "0" + snum;}
        document.getElementById("timeDate").innerHTML = "本站已安全运行 "+dnum+" 天 ";
        document.getElementById("times").innerHTML = hnum + " 小时 " + mnum + " 分 " + snum + " 秒";
    }
setInterval("createtime()",250);
</script>
</div>
      </footer>

      <div class="back-to-top" id="back-to-top">
        <i class="iconfont icon-up"></i>
      </div>
    </div>
    


    


    




  
    <script type="text/javascript" src="/lib/jquery/jquery-3.1.1.min.js"></script>
  

  

    <script type="text/javascript" src="/js/src/theme.js?v=1.1"></script>
<script type="text/javascript" src="/js/src/bootstrap.js?v=1.1"></script>

    

  
  <script type="application/ld+json">
  {
  "@context": "http://www.schema.org",
  "@type": "Person",
  "@id": "https://huangyijie.com/about/",
  "name": "黄奕杰",
  "alternateName": "Henry Huang",
  "nationality": "中国",
  "birthPlace" : {
    "@type": "Place",
      "address": {
        "@type": "PostalAddress",
      "addressLocality": "汕头市",
      "addressRegion": "广东省",
          "addressCountry": "中国"
    }
  },
  "gender": "Male",
  "Description": "Software Engineer",
  "disambiguatingDescription": "Full stack software engineer, focus on Java and JavaScript.",
  "jobTitle": "Software Engineer",
  "url": "https://huangyijie.com",
  "image": "https://s.gravatar.com/avatar/4e0e61fdf1b2bcfb4ee31da27601fe6b?s=512&r=g",
  "address": {
    "@type": "PostalAddress",
    "addressLocality": "深圳市",
    "addressRegion": "广东省",
    "addressCountry": "中国"
  },
  "sameAs": [
    "http://weibo.com/626242034",
    "https://github.com/henryhuang",
    "https://unsplash.com/@henryhh"
    ]
  }
  </script>
  </body>
</html>
